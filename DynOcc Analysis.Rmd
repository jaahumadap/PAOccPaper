---
title: "Simulation analysis - dynamic models"
author: "Jorge A. Ahumada"
date: "March 22, 2016"
output: html_document
---

```{r setup, include=FALSE}
library(unmarked)
library(ggplot2)
library(parallel)
library(foreach)
library(doParallel)

gm_mean = function(x, na.rm=TRUE, zero.propagate = FALSE){
  if(any(x < 0, na.rm = TRUE)){
    return(NaN)
  }
  if(zero.propagate){
    if(any(x == 0, na.rm = TRUE)){
      return(0)
    }
    exp(mean(log(x), na.rm = na.rm))
  } else {
    exp(sum(log(x[x > 0]), na.rm=na.rm) / length(x))
  }
}
```

### Function to simulate the data
Using this function to simulate a dynamic occupancy model with *n* points, *t* years (primary periods), *d* days (secondary periods), initial occupancy $\psi$, survival probability $\phi$, colonization probability $\gamma$ and detection probabilty *p*:
```{r cars}
data.generator<-function(points,days,psi,p,phi,gamma,years) {
        require(unmarked)
        #first year of data
        y1<-matrix(NA,nr=points,nc=days)
        #generate the expected occupancies
        z<-rbinom(points,1,psi)
        #generate the observations
        for(i in 1:points)
                y1[i,]<-rbinom(days,1,z[i]*p)
        #subsequent years
        #three dimensional matrix to store the results
        yk<-array(NA,dim=c(points,days,years))
        yk[,,1]<-y1
        for(k in 2:years){
        #generate the deterministic part of the model
                occ<-apply(yk[,,k-1],1,max,na.rm=T)
                z<-rbinom(points,1,occ*phi+(1-occ)*gamma)
        #generate the observations
        for(i in 1:points)
                yk[i,,k]<-rbinom(days,1,z[i]*p)
     
        }  
        # convert results to a two dimensional matrix for colext
        yk <- matrix(yk, points, days*years)
        #ny <- matrix(as.character(1:years),nrow(yk), years, byrow=TRUE)
        # store data in an unmarkedMultFrame object so it is ready for analysis
        yUMF <- unmarkedMultFrame(y = yk, numPrimary = years)
        yUMF
 } 
```
Simulate some data:
```{r}
set.seed(400)
data <- data.generator(points = 30,days = 30, psi = 0.5, p = 0.5, phi = 0.2, 
                       gamma = 0, years = 5)

#Look at the first year of data
summary(data)
```
Now, fit a dynamic occupancy model using colext
```{r}
model <- colext(psiformula = ~1,gammaformula = ~1,epsilonformula = ~1, 
                pformula = ~1, data = data, method = "BFGS",se = FALSE)
summary(model)
backTransform(model,type=c("psi"))
backTransform(model,type=c("col"))
backTransform(model,type=c("ext"))
backTransform(model,type=c("det"))
```
Now compare the naive occupancy from the simulation to the fitted occupancy:
```{r}
data3d <- array(data@y,dim = c(30,30,5))
obs <- apply( apply(data3d, c(1,3), max, na.rm = T), 2, sum) / nrow(data3d)
# Estimate the projected trajectory - prediction of occupancy based on an infinite sample of sites
mod <- as.numeric(projected(model)[2,])
# Estimate the smoothed trajectory - prediction of occupancy based on the actual sampled sites
mods <- as.numeric(smoothed(model)[2,])

plot(1:5, obs, type="p",ylim=c(0,1)); lines(1:5, mod); lines(1:5, mods, lty=2)
#abs(mod-obs); abs(mods-obs)
```
Here is a function that repats this process for an arbitrary number of simulations *nsim* and also fits a logistic regression for each simulation, returning both the time series and the parameters of the logistic regression:

```{r = simulatetredn function}
simulatetrend <- function(points = 10,days = 30, psi = 0.5, p = 0.2, phi = 0.2, gamma = 0, years = 5, nsim = 5) {
        #store results
        #gm_lambda <- numeric()
        time <- 1:years
        results <- foreach(i = 1:nsim, .combine = rbind, .packages = "unmarked", .export = c("data.generator","gm_mean")) %dopar% {
                #generate data and store projected results
                data <- data.generator(points,days,psi,p,phi,gamma,years)
                model <- colext(~1, ~1, ~1, ~1, data = data, method = "BFGS",se = FALSE)
                timeseries <- as.numeric(smoothed(model)[2,])
                
                #calculate difference between year 1 and year n
                diff1_n <- timeseries[1] - timeseries[-1]
                
                #Calculate geometric mean of lambda
                lambda <- timeseries[2:years]/timeseries[1:(years-1)]
                lambda <- -(gm_mean(lambda) - 1)
                c(timeseries,diff1_n,lambda)
        }
        results
        #list(gmlambda = gm_lambda, results = results)
}
```
Running *simulatetrend* with 100 simulations and a 10% decrease in occupancy:


```{r, echo = FALSE}
# Setting up the machine for parallel processing
no_cores <- detectCores() - 1
cl<-makeCluster(no_cores)
registerDoParallel(cl)
```
```{r, cache = TRUE}
# Run a simulation
test <- simulatetrend(points = 60, psi = 0.2, gamma = 0, phi = 0.95, nsim = 200, years = 10)
```
and then graphing the results:
```{r,echo=FALSE}
stopCluster(cl)

res <- data.frame(test)
slopes <- data.frame(slopes = test[,ncol(res)])
changes <- data.frame(test[,(ncol(res)/2+1):(ncol(res)-1)])
res <- res[,-c((ncol(res)/2+1):(ncol(res)))]
res <- data.frame(res, id = 1:nrow(res))
names(res) <- c(1:(ncol(res)-1), "id")

res <- melt(res,c("id"), variable_name = "year")
#names(res)[2] <- "year"
ggplot(res, aes(x=year, y= value)) + geom_violin() + geom_line(aes(group=id),alpha=0.2)

```
examine the distribution of the geometric mean of $\lambda=\frac{\psi_{t+1}}{\psi_t}$
```{r, echo = FALSE, message=FALSE}
ggplot(slopes,aes(x=slopes)) + geom_histogram() + geom_density()
```
and the number of years it takes to detect the change
```{r}
names(changes) <- c(1:ncol(changes))
confint <- apply(changes,2,quantile,c(0.1,0.9))
#year where change is
#round(confint,digits = 2)
y <- which(round(confint[1,],2) > 0)
ifelse(length(y)==0,0,min(y))

#graph the results
changes <- melt(changes, variable_name = "year")
ggplot(changes, aes(x=year, y= value)) + geom_violin() + ylab("year(1) - year(n)")
```